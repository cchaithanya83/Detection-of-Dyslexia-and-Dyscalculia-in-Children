{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted synthetic dataset generated and saved as 'adjusted_synthetic_dyslexia_dyscalculia_dataset.csv'.\n",
      "   Reading_Speed  Reading_Accuracy  Math_Speed  Math_Accuracy  Memory_Score  \\\n",
      "0      55.748192         65.516790   81.103747      86.115122     78.055167   \n",
      "1      50.027020         50.867944   30.227170      33.583593     82.647456   \n",
      "2     102.547636         96.114361   87.478147      90.709620     86.206359   \n",
      "3      59.792882         66.231645   80.456096      88.353716     66.197879   \n",
      "4      64.999556         73.623427   94.415591      90.971553     82.894646   \n",
      "\n",
      "  Condition  \n",
      "0  dyslexia  \n",
      "1      both  \n",
      "2    normal  \n",
      "3  dyslexia  \n",
      "4  dyslexia  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples for each class\n",
    "n_samples = 500\n",
    "\n",
    "# Helper function to generate data\n",
    "def generate_data(n, condition):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        if condition == \"dyslexia\":\n",
    "            reading_speed = np.random.uniform(50, 70)  # Words per minute (lower)\n",
    "            reading_accuracy = np.random.uniform(60, 75)  # Percentage (lower)\n",
    "            math_speed = np.random.uniform(80, 99)  # Math problems per hour (slightly lower)\n",
    "            math_accuracy = np.random.uniform(85, 95)  # Math accuracy percentage (normal)\n",
    "        elif condition == \"dyscalculia\":\n",
    "            reading_speed = np.random.uniform(90, 110)  # Words per minute (normal)\n",
    "            reading_accuracy = np.random.uniform(90, 99)  # Percentage (normal)\n",
    "            math_speed = np.random.uniform(30, 50)  # Math problems per hour (lower)\n",
    "            math_accuracy = np.random.uniform(40, 60)  # Math accuracy percentage (lower)\n",
    "        elif condition == \"both\":\n",
    "            reading_speed = np.random.uniform(40, 60)  # Words per minute (lower)\n",
    "            reading_accuracy = np.random.uniform(50, 70)  # Percentage (lower)\n",
    "            math_speed = np.random.uniform(25, 40)  # Math problems per hour (lower)\n",
    "            math_accuracy = np.random.uniform(30, 50)  # Math accuracy percentage (lower)\n",
    "        else:  # Normal (control group)\n",
    "            reading_speed = np.random.uniform(99, 120)  # Words per minute\n",
    "            reading_accuracy = np.random.uniform(95, 99)  # Percentage\n",
    "            math_speed = np.random.uniform(85, 99)  # Math problems per hour\n",
    "            math_accuracy = np.random.uniform(90, 98)  # Math accuracy percentage\n",
    "\n",
    "        # attention_span = np.random.uniform(70 if condition in [\"dyslexia\", \"dyscalculia\", \"both\"] else 90, 95)  # Percentage\n",
    "        memory_score = np.random.uniform(60 if condition in [\"dyslexia\", \"dyscalculia\", \"both\"] else 85, 95)  # Percentage\n",
    "\n",
    "        data.append([\n",
    "            reading_speed,\n",
    "            reading_accuracy,\n",
    "            math_speed,\n",
    "            math_accuracy,\n",
    "            # attention_span,\n",
    "            memory_score,\n",
    "            condition\n",
    "        ])\n",
    "    return data\n",
    "\n",
    "# Generate synthetic data for each condition\n",
    "data_normal = generate_data(n_samples, \"normal\")\n",
    "data_dyslexia = generate_data(n_samples, \"dyslexia\")\n",
    "data_dyscalculia = generate_data(n_samples, \"dyscalculia\")\n",
    "data_both = generate_data(n_samples, \"both\")\n",
    "\n",
    "# Combine all data\n",
    "columns = [\n",
    "    \"Reading_Speed\", \n",
    "    \"Reading_Accuracy\", \n",
    "    \"Math_Speed\", \n",
    "    \"Math_Accuracy\", \n",
    "    # \"Attention_Span\", \n",
    "    \"Memory_Score\", \n",
    "    \"Condition\"\n",
    "]\n",
    "all_data = pd.DataFrame(data_normal + data_dyslexia + data_dyscalculia + data_both, columns=columns)\n",
    "\n",
    "# Shuffle the dataset\n",
    "all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save to a CSV file\n",
    "all_data.to_csv(\"adjusted_synthetic_dyslexia_dyscalculia_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Adjusted synthetic dataset generated and saved as 'adjusted_synthetic_dyslexia_dyscalculia_dataset.csv'.\")\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted synthetic dataset with overlaps generated and saved as 'adjusted_synthetic_dyslexia_dyscalculia_dataset.csv'.\n",
      "   Reading_Speed  Reading_Accuracy  Math_Speed  Math_Accuracy  Memory_Score  \\\n",
      "0     118.428563         98.705736  112.244517      86.440654     89.434523   \n",
      "1      44.784194         71.740328   16.722199      32.627295     89.047384   \n",
      "2     104.100113         83.325139   16.083636      28.797541     81.282234   \n",
      "3      60.125712         70.720012   52.274211      49.248349     95.495792   \n",
      "4      50.879727         45.376231   65.804911      85.473059     71.661722   \n",
      "\n",
      "     Condition  \n",
      "0       normal  \n",
      "1         both  \n",
      "2  dyscalculia  \n",
      "3         both  \n",
      "4     dyslexia  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples for each class\n",
    "n_samples = 3000\n",
    "\n",
    "# Helper function to generate data\n",
    "def generate_data(n, condition):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        if condition == \"dyslexia\":\n",
    "            reading_speed = np.random.uniform(10, 60)  # Overlap with normal\n",
    "            reading_accuracy = np.random.uniform(10, 75)  # Overlap with normal\n",
    "            math_speed = np.random.uniform(65, 90)  # Overlap with normal\n",
    "            math_accuracy = np.random.uniform(70, 95)  # Overlap with dyscalculia\n",
    "        elif condition == \"dyscalculia\":\n",
    "            reading_speed = np.random.uniform(70, 140)  # Overlap with normal\n",
    "            reading_accuracy = np.random.uniform(80, 99)  # Overlap with normal\n",
    "            math_speed = np.random.uniform(10, 70)  # Overlap with both\n",
    "            math_accuracy = np.random.uniform(10, 70)  # Overlap with both\n",
    "        elif condition == \"both\":\n",
    "            reading_speed = np.random.uniform(10, 70)  # Overlap with dyslexia\n",
    "            reading_accuracy = np.random.uniform(10, 75)  # Overlap with dyslexia\n",
    "            math_speed = np.random.uniform(10, 65)  # Overlap with dyscalculia\n",
    "            math_accuracy = np.random.uniform(5, 60)  # Overlap with dyscalculia\n",
    "        else:  # Normal (control group)\n",
    "            reading_speed = np.random.uniform(80, 140)  # Slight overlap with dyslexia\n",
    "            reading_accuracy = np.random.uniform(85, 99)  # Slight overlap with dyslexia and dyscalculia\n",
    "            math_speed = np.random.uniform(70, 140)  # Slight overlap with dyslexia\n",
    "            math_accuracy = np.random.uniform(80, 98)  # Slight overlap with dyslexia\n",
    "\n",
    "        # Slight overlap for attention span and memory score\n",
    "        # attention_span = np.random.uniform(75 if condition in [\"dyslexia\", \"dyscalculia\", \"both\"] else 85, 95)\n",
    "        memory_score = np.random.uniform(65 if condition in [ \"dyscalculia\", \"both\"] else 70, 100)\n",
    "\n",
    "        data.append([\n",
    "            reading_speed,\n",
    "            reading_accuracy,\n",
    "            math_speed,\n",
    "            math_accuracy,\n",
    "            # attention_span,\n",
    "            memory_score,\n",
    "            condition\n",
    "        ])\n",
    "    return data\n",
    "\n",
    "# Generate synthetic data for each condition\n",
    "data_normal = generate_data(n_samples, \"normal\")\n",
    "data_dyslexia = generate_data(n_samples, \"dyslexia\")\n",
    "data_dyscalculia = generate_data(n_samples, \"dyscalculia\")\n",
    "data_both = generate_data(n_samples, \"both\")\n",
    "\n",
    "# Combine all data\n",
    "columns = [\n",
    "    \"Reading_Speed\", \n",
    "    \"Reading_Accuracy\", \n",
    "    \"Math_Speed\", \n",
    "    \"Math_Accuracy\", \n",
    "    # \"Attention_Span\", \n",
    "    \"Memory_Score\", \n",
    "    \"Condition\"\n",
    "]\n",
    "all_data = pd.DataFrame(data_normal + data_dyslexia + data_dyscalculia + data_both, columns=columns)\n",
    "\n",
    "# Shuffle the dataset\n",
    "all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save to a CSV file\n",
    "all_data.to_csv(\"adjusted_synthetic_dyslexia_dyscalculia_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Adjusted synthetic dataset with overlaps generated and saved as 'adjusted_synthetic_dyslexia_dyscalculia_dataset.csv'.\")\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Accuracy for Random Forest: 0.9998\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       1.00      1.00      1.00      2968\n",
      " dyscalculia       1.00      1.00      1.00      2970\n",
      "    dyslexia       1.00      1.00      1.00      2974\n",
      "      normal       1.00      1.00      1.00      2968\n",
      "\n",
      "    accuracy                           1.00     11880\n",
      "   macro avg       1.00      1.00      1.00     11880\n",
      "weighted avg       1.00      1.00      1.00     11880\n",
      "\n",
      "Training SVM...\n",
      "Accuracy for SVM: 0.9978\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       1.00      0.99      1.00      2968\n",
      " dyscalculia       0.99      1.00      1.00      2970\n",
      "    dyslexia       1.00      1.00      1.00      2974\n",
      "      normal       1.00      1.00      1.00      2968\n",
      "\n",
      "    accuracy                           1.00     11880\n",
      "   macro avg       1.00      1.00      1.00     11880\n",
      "weighted avg       1.00      1.00      1.00     11880\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "Accuracy for K-Nearest Neighbors: 0.9880\n",
      "Classification Report for K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       1.00      0.96      0.98      2968\n",
      " dyscalculia       0.97      0.99      0.98      2970\n",
      "    dyslexia       0.99      1.00      0.99      2974\n",
      "      normal       0.99      1.00      1.00      2968\n",
      "\n",
      "    accuracy                           0.99     11880\n",
      "   macro avg       0.99      0.99      0.99     11880\n",
      "weighted avg       0.99      0.99      0.99     11880\n",
      "\n",
      "Training Logistic Regression...\n",
      "Accuracy for Logistic Regression: 0.9950\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       1.00      0.98      0.99      2968\n",
      " dyscalculia       0.99      1.00      0.99      2970\n",
      "    dyslexia       0.99      1.00      1.00      2974\n",
      "      normal       1.00      1.00      1.00      2968\n",
      "\n",
      "    accuracy                           1.00     11880\n",
      "   macro avg       1.00      1.00      1.00     11880\n",
      "weighted avg       1.00      1.00      1.00     11880\n",
      "\n",
      "Training Naive Bayes...\n",
      "Accuracy for Naive Bayes: 1.0000\n",
      "Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       1.00      1.00      1.00      2968\n",
      " dyscalculia       1.00      1.00      1.00      2970\n",
      "    dyslexia       1.00      1.00      1.00      2974\n",
      "      normal       1.00      1.00      1.00      2968\n",
      "\n",
      "    accuracy                           1.00     11880\n",
      "   macro avg       1.00      1.00      1.00     11880\n",
      "weighted avg       1.00      1.00      1.00     11880\n",
      "\n",
      "\n",
      "Summary of Model Performance:\n",
      "                 Model  Accuracy\n",
      "0        Random Forest  0.999832\n",
      "1                  SVM  0.997811\n",
      "2  K-Nearest Neighbors  0.988047\n",
      "3  Logistic Regression  0.995034\n",
      "4          Naive Bayes  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"adjusted_synthetic_dyslexia_dyscalculia_dataset.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[\"Condition\"])\n",
    "y = data[\"Condition\"]\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.99, random_state=42)\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=5)  # Select top 5 features\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=3, scoring=\"accuracy\")\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Hyperparameter tuning for SVM\n",
    "svm_params = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "}\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_grid = GridSearchCV(svm_model, svm_params, cv=3, scoring=\"accuracy\")\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Initialize other models\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "lr_model = LogisticRegression(random_state=42, penalty='l2', C=0.5)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train and evaluate all models\n",
    "models = {\n",
    "    \"Random Forest\": rf_grid.best_estimator_,\n",
    "    \"SVM\": svm_grid.best_estimator_,\n",
    "    \"K-Nearest Neighbors\": knn_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Naive Bayes\": nb_model,\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {model_name}: {acc:.4f}\")\n",
    "    print(f\"Classification Report for {model_name}:\\n{classification_report(y_test, y_pred, target_names=label_encoder.classes_)}\")\n",
    "    \n",
    "    results.append((model_name, acc))\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"])\n",
    "print(\"\\nSummary of Model Performance:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(\"model_performance_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model saved as knn_model.pkl\n",
      "Scaler saved as scaler.pkl\n",
      "Feature selector saved as selector.pkl\n",
      "Label encoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the KNN model to a file\n",
    "knn_model_filename = \"knn_model.pkl\"\n",
    "joblib.dump(knn_model, knn_model_filename)\n",
    "print(f\"KNN model saved as {knn_model_filename}\")\n",
    "\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = \"scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler saved as {scaler_filename}\")\n",
    "\n",
    "# Save the feature selector\n",
    "selector_filename = \"selector.pkl\"\n",
    "joblib.dump(selector, selector_filename)\n",
    "print(f\"Feature selector saved as {selector_filename}\")\n",
    "\n",
    "\n",
    "# Save the label encoder to a file\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"Label encoder saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Condition: dyscalculia\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved KNN model, scaler, and feature selector\n",
    "knn_model = joblib.load(\"knn_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "selector = joblib.load(\"selector.pkl\")\n",
    "\n",
    "# Define the function for prediction\n",
    "def predict_condition(features):\n",
    "    \"\"\"\n",
    "    Predict the condition using the KNN model.\n",
    "\n",
    "    Parameters:\n",
    "    - features: list or np.ndarray\n",
    "        A list or 1D array containing feature values in the same order as the training data.\n",
    "\n",
    "    Returns:\n",
    "    - prediction: str\n",
    "        Predicted condition label.\n",
    "    \"\"\"\n",
    "    # Ensure the input is a numpy array\n",
    "    features = np.array(features).reshape(1, -1)\n",
    "\n",
    "    # Apply feature selection\n",
    "    selected_features = selector.transform(features)\n",
    "\n",
    "    # Scale the features\n",
    "    scaled_features = scaler.transform(selected_features)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction_encoded = knn_model.predict(scaled_features)\n",
    "\n",
    "    # Decode the prediction to its original label\n",
    "    prediction_label = label_encoder.inverse_transform(prediction_encoded)\n",
    "    \n",
    "    return prediction_label[0]\n",
    "\n",
    "\n",
    "    # Example input values (ensure they are in the correct order)\n",
    "# example_features = [117.66188132791392,100.06116117124812,80.13248169221794,99.27262613533308,89.54033049802344,98.90247500836509]  # Replace with actual feature values\n",
    "example_features = [50,76,40,50,95]  # Replace with actual feature values\n",
    "\n",
    "    # Get the prediction\n",
    "predicted_condition = predict_condition(example_features)\n",
    "print(f\"Predicted Condition: {predicted_condition}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
